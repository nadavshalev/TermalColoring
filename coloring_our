import keras
import os
import numpy as np
import skimage
from net_functions import *


def get_model():
    ly = keras.layers
    md = keras.models

    # Encoder
    encoder_input = ly.Input(shape=(256, 256, 1,))
    encoder_output = ly.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)(encoder_input)
    encoder_output = ly.Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_output)
    encoder_output = ly.Conv2D(128, (3, 3), activation='relu', padding='same', strides=2)(encoder_output)
    encoder_output = ly.Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)
    encoder_output = ly.Conv2D(256, (3, 3), activation='relu', padding='same', strides=2)(encoder_output)
    encoder_output = ly.Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)
    encoder_output = ly.Conv2D(512, (3, 3), activation='relu', padding='same')(encoder_output)
    encoder_output = ly.Conv2D(256, (3, 3), activation='relu', padding='same')(encoder_output)

    # Decoder
    decoder_output = ly.Conv2D(128, (3, 3), activation='relu', padding='same')(encoder_output)
    decoder_output = ly.UpSampling2D((2, 2))(decoder_output)
    decoder_output = ly.Conv2D(64, (3, 3), activation='relu', padding='same')(decoder_output)
    decoder_output = ly.UpSampling2D((2, 2))(decoder_output)
    decoder_output = ly.Conv2D(32, (3, 3), activation='relu', padding='same')(decoder_output)
    decoder_output = ly.Conv2D(16, (3, 3), activation='relu', padding='same')(decoder_output)
    decoder_output = ly.Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)
    decoder_output = ly.UpSampling2D((2, 2))(decoder_output)

    return md.Model(inputs=encoder_input, outputs=decoder_output)



load_model = True
val_split = 0.2
batch_size = 50
epochs = 3

path_test = '../../data/colorIm/testdata/Validate/'
path_train = '../../data/colorIm/images/Train/'
path_res = './results/'
filepath="./chechpoints/model-{epoch:02d}-{val_acc:.2f}.hdf5"

# load images from folder
#data_train, data_val, data_test = load_data(path_test=path_test, path_train=path_train, val_size=val_split, train_num=500)

# load images from file
data_train, data_val, data_test = load_from_file()

# preproces data
X_train, Y_train = get_data_labels(data_train)
X_val, Y_val = get_data_labels(data_val)

# get model and compile
if load_model:
    #model.load_weights("weights.best.hdf5")
    model = keras.models.load_model('./chechpoints/model-03-0.56.hdf5')
else:
    model = get_model()
    model.compile(optimizer='adam', loss='mae', metrics=['accuracy'])

    # set data aug
    datagen = keras.preprocessing.image.ImageDataGenerator(
            shear_range=0.2,
            zoom_range=0.2,
            rotation_range=20,
            horizontal_flip=True)
    datagen.fit(X_train)

    # set checkpoints
    checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')
    callbacks_list = [checkpoint]

    # train model
    model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size),
                        steps_per_epoch=len(X_train) / batch_size, epochs=epochs,
                        validation_data=datagen.flow(X_val, Y_val, batch_size=batch_size),
                        validation_steps=len(X_val) / batch_size, validation_freq=1,
                        workers=4, use_multiprocessing=True, shuffle=True,
                        initial_epoch=0, callbacks=callbacks_list)

# predict and save to folder
output = model.predict(data_test) * 128
save_results(output, data_test, path_res)

pass